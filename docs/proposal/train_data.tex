\section{Training data}

Open source code to train both the CBOW and the skip-gram architectures have been released by Google [7]. 
We also have access to 30 million vector representations of words trained on Googleâ€™s original training data. 
In addition to the above, we intend to run the training algorithm on freely available text data such as the entire corpus of wikipedia in order to conduct our experiments. 
The algorithm trains on sentences preprocessed to have punctuations removed and phrases (such as ice-cream) appended together. 

