\section{Conclusion}

In conclusion, this report details our investigations into neural language models and the properties of the continuous vector representations that result from training these models. We show that having more data results in vectors whose linear properties are more amenable for use in finding analogies. We conjecture that the vast amounts of data that Google trains these models on allows the vectors to consistently outperform any models that we train when evaluated on the analogical reasoning dataset. We visualize the underlying structure of the linear properties and see that there exists some noisy linear structure in two and three dimensions. Our results from  clustering finds analogies absent in the original test set. Such a model could be used by asking which cluster a new vector offset pair fits best in. Most of our work was done using the vectors provided by Google. It would be interesting to see if we could still find interesting analogies when the models are trained with limited data. While clustering analogies does indeed let us find interesting analogies. We are currently evaluating supervised linear models to predict different kinds of analogies when given a pairs of vector offsets. 